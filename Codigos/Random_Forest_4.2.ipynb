{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Random Forest 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Implementación más profesional del random forest con gridsearch y cross validation, con los datos de tiempos. <br>\n",
    "**nota:** ya no se fijará la random seed. Se usará un split predefinido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paquetes\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import make_scorer, recall_score, confusion_matrix, classification_report\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos los datos\n",
    "df_import = pd.read_csv('df_datos_tiempos.csv', index_col='Unnamed: 0')\n",
    "train_ids = list(pd.read_csv('splits/train_ids634.csv', header=None)[0])\n",
    "test_ids = list(pd.read_csv('splits/test_ids634.csv', header=None)[0])\n",
    "\n",
    "# llenamos los train-test splits\n",
    "df_train = df_import[df_import['id_ecg'].isin(train_ids)].copy()\n",
    "df_test = df_import[df_import['id_ecg'].isin(test_ids)].copy()\n",
    "\n",
    "# separamos las variables predictivas\n",
    "X_train = df_train.drop(columns = ['id_ecg','categoria','patient_id']).copy()\n",
    "X_test = df_test.drop(columns = ['id_ecg','categoria','patient_id']).copy()\n",
    "\n",
    "# codificamos las categorías\n",
    "label_encoder = LabelEncoder()\n",
    "categorias = df_import['categoria'].unique()\n",
    "label_encoder.fit(categorias)\n",
    "\n",
    "# generamos la variable objetivo\n",
    "y_train = label_encoder.transform(df_train['categoria'])\n",
    "y_test = label_encoder.transform(df_test['categoria'])\n",
    "\n",
    "# vamos a imprimir los resultados del splitting\n",
    "train_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "porcentaje_train = train_size/(train_size+test_size)\n",
    "porcentaje_test = test_size/(train_size+test_size)\n",
    "print()\n",
    "print(f'\\033[1m tenemos {train_size:d} eventos para el training ({porcentaje_train:.2%}). \\033[0m') # f-strings y negritas\n",
    "print()\n",
    "print(f'\\033[1m tenemos {test_size:d} eventos para el testing ({porcentaje_test:.2%}). \\033[0m') # f-strings y negritas\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el modelo abstracto de gridsearch con cross validation\n",
    "\n",
    "# definimos el random forest. Los parámetros se definirán en el gridsearch\n",
    "rf_abstracto = RandomForestClassifier()\n",
    "\n",
    "# método de foldeo\n",
    "cross_validation_strategy = StratifiedKFold(n_splits=5, # reducimos el número de splits para optimizar el proceso\n",
    "                                            shuffle=True)\n",
    "\n",
    "# método de scoring por recall\n",
    "recall_scorer = make_scorer(recall_score, average='macro')\n",
    "\n",
    "# hacemos cálculos para hacer una lista artesanal de posibles valores en max_features.\n",
    "n_features = X_train.shape[1] # vemos cuantas features tenemos\n",
    "sqrt_n = np.round(np.sqrt(n_features),0) # calculamos la raíz cuadrada y redondeamos\n",
    "raiz_n = np.round(np.log2(n_features),0) # calculamos el logaritmo base 2 y redondeamos\n",
    "otros_valores = [1,5,10,15,20,25] # mas valores manuales para max_features\n",
    "opciones_max_features = sorted(list(set([n_features,sqrt_n,raiz_n]+otros_valores))) # generamos una lista ordenada y sin repetidos\n",
    "opciones_max_features = [int(x) for x in opciones_max_features] # para evitar errores de formato, pasamos a int\n",
    "\n",
    "# hacemos el diccionario de hiperparámetros para el gridsearch\n",
    "parametros_gridsearch = {'n_estimators':[25,50,75,100,125,150], # hiperparámetro a modificar 1: número de árboles\n",
    "                         'max_features':opciones_max_features, # hiperparámetro a modificar 2: número de variables para la cosntrucción de árboles\n",
    "                         'min_samples_split':[2,20,40,60]} # hiperparámetro a modificar 3: número de eventos para dividir rama\n",
    "\n",
    "#gridsearch: ejecutar CrossValidation con diferentes parámetros.\n",
    "gridsearch_abstracto = GridSearchCV(estimator=rf_abstracto,\n",
    "                                    param_grid=parametros_gridsearch, # usamos el diccionario creado arriba\n",
    "                                    scoring=recall_scorer, # usamos el método de scoring por recall\n",
    "                                    n_jobs=-2, # -2 indica que todos los procesadores serán usados menos uno.\n",
    "                                    refit=False, # NO recalculará un modelo con los mejores parámetros y todos los datos.\n",
    "                                    cv=cross_validation_strategy,\n",
    "                                    error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciamos el timer\n",
    "tiempo_inicio = time.time()\n",
    "\n",
    "# ejecutamos gridsearch con las bases de datos\n",
    "gridsearch = gridsearch_abstracto.fit(X_train, y_train)\n",
    "\n",
    "# concluimos el timer\n",
    "tiempo_final = time.time()\n",
    "\n",
    "print(f'la ejecución del gridsearch tomó {(tiempo_final-tiempo_inicio)/60:.2f} minutos.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a visualizar los resultados\n",
    "\n",
    "# guardamos los resultados que nos interesan\n",
    "gridsearch_resultados = gridsearch.cv_results_ # aquí están todos los resultados resumidos\n",
    "parametros = gridsearch_resultados['params'] # guardamos los parámetros y...\n",
    "resultados = gridsearch_resultados['mean_test_score'] # el resultado del modelo con esos parámetros.\n",
    "\n",
    "# guardamos el i-esimo resultado con sus parámetros\n",
    "for i, dic in enumerate(parametros):\n",
    "    dic.update({'accuracy':resultados[i]})\n",
    "\n",
    "# vemos cuales parametros tenemos\n",
    "valores_n_estimators = np.unique([p['n_estimators'] for p in parametros])\n",
    "valores_max_features = np.unique([p['max_features'] for p in parametros])\n",
    "valores_min_samples_split = np.unique([p['min_samples_split'] for p in parametros])\n",
    "\n",
    "# vamos a hacer muchas graficas con los diferentes valores de min_samples_split con un loop\n",
    "matriz0 = np.zeros((len(valores_n_estimators),len(valores_max_features)))\n",
    "\n",
    "for k, split in enumerate(valores_min_samples_split):\n",
    "    \n",
    "    #creamos el dataframe con ceros\n",
    "    df_resultados = pd.DataFrame(data = matriz0,\n",
    "                                 index=valores_n_estimators,\n",
    "                                 columns=valores_max_features)\n",
    "    \n",
    "    # llenamos el dataframe\n",
    "    for i, n_estimator in enumerate(valores_n_estimators):\n",
    "        for j, max_feature in enumerate(valores_max_features):\n",
    "            df_resultados.iloc[i,j] = [x['accuracy'] for x in parametros \n",
    "                                       if (x['min_samples_split']==split) \n",
    "                                       and (x['n_estimators']==n_estimator) \n",
    "                                       and (x['max_features']==max_feature)][0]\n",
    "    \n",
    "    # graficamos\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(df_resultados.iloc[::-1], cmap='Paired', vmin=0.45, vmax=0.55)\n",
    "    plt.title('min samples split = '+str(split))\n",
    "    plt.ylabel(\"Número de árboles\")\n",
    "    plt.xlabel(\"Número de variables\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearmamos el mejor modelo\n",
    "mejor_modelo_abstracto = RandomForestClassifier(n_estimators=gridsearch.best_params_['n_estimators'],\n",
    "                                                criterion='gini',\n",
    "                                                max_depth=None,\n",
    "                                                min_samples_split=gridsearch.best_params_['min_samples_split'],\n",
    "                                                max_features=gridsearch.best_params_['max_features'],\n",
    "                                                bootstrap=True)\n",
    "# entrenamos el mejor modelo\n",
    "mejor_modelo = mejor_modelo_abstracto.fit(X=X_train, y=y_train)\n",
    "\n",
    "# predecimos con el mejor modelo\n",
    "y_prediccion = mejor_modelo.predict(X_test)\n",
    "\n",
    "# calculamos los resultados\n",
    "matriz_confusion = confusion_matrix(y_true=y_test, y_pred=y_prediccion)\n",
    "\n",
    "# imprimimos los parametros optimos\n",
    "df_mejor_modelo = pd.DataFrame(list(gridsearch.best_params_.items()),\n",
    "                               columns=['parametro','valor óptimo'])\n",
    "print(df_mejor_modelo.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimimos la matriz de confusion\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(matriz_confusion,\n",
    "            annot=True, # anotar valor en cada cuadro\n",
    "            fmt='d', # formato del valor que se mostrará en cada cuadro. 'd' hace referencia a 'sin decimales'\n",
    "            cmap='Blues', # le estamos diciendo que use colores azules\n",
    "            xticklabels=label_encoder.classes_, # leyenda del eje x\n",
    "            yticklabels=label_encoder.classes_) # leyenda del eje y\n",
    "plt.xlabel('Predicción') # título eje x\n",
    "plt.ylabel('Condición Real') # título eje y\n",
    "plt.title('Matriz de Confusión - Diagnóstico ECG') # título del gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabla de resultados\n",
    "# precision = True Positive / (True Positive + False Positive) = De los que predijiste con padecimiento X, cuántos si tienen el padecimiento.\n",
    "# recall = True Positive / (True Positive + False Negative) = De los que tienen padecimiento X, cuántos predijiste correctamente.\n",
    "# f1-score = Media armónica de precisión y recall = Penaliza valores bajos, por lo que ambos valores deben ser buenos para un valor alto.\n",
    "# support = tamaño de muestra\n",
    "# acurracy = precisión global = (Global True Positives + Global True Negatives) / number of events\n",
    "# macro average = promedio de la columna\n",
    "# weighted average = promedio de la columna ponderado por su tamaño de muestra\n",
    "print(\"                 \" + \"\\033[1m\" + 'Reporte de clasificación' + \"\\033[1m\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_prediccion, target_names=label_encoder.classes_))\n",
    "print(\"(accuracy en cross-validation: \" + str(gridsearch.best_score_) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
