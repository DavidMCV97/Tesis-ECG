{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Random Forest 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "En este segundo notebook hacemos random forest con Cross Validation para practicar la implementación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paquetes\n",
    "import pandas as pd # para maenejar dataframes\n",
    "from sklearn.preprocessing import LabelEncoder # para codificar las categorías\n",
    "from sklearn.model_selection import train_test_split # para dividir la base de datos en train/test\n",
    "from sklearn.ensemble import RandomForestClassifier # para implementar random forest\n",
    "from sklearn.model_selection import cross_validate # para hacer cross validation\n",
    "from sklearn.model_selection import KFold # para la estrategia de división de cross validation\n",
    "import matplotlib.pyplot as plt # para graficar\n",
    "from numpy import mean # para sacar promedios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos los pasos del Random_Forest_1\n",
    "\n",
    "# importamos los datos\n",
    "df_import = pd.read_csv('df_datos.csv', index_col='Unnamed: 0')\n",
    "\n",
    "# separamos las variables predictivas (X) de la categoría (y)\n",
    "df_X = df_import.drop(columns = ['id_ecg','categoria','patient_id'])\n",
    "ps_y = df_import['categoria'] # ps = pandas series\n",
    "\n",
    "# label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "ps_y_encoded = label_encoder.fit_transform(ps_y)\n",
    "\n",
    "# vamos a dividir los datos para el grupo de entrenamiento y el de prueba.\n",
    "# este punto es tricky. Vamos a hacer la cross validatión solo con los conjuntos de entrenamiento, el conjunto de test se deja aparte.\n",
    "# no es tan necesario si no se va a hacer gridsearch\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, # variables predictivas\n",
    "                                                    ps_y_encoded, # variable objetivo (ya codificada)\n",
    "                                                    test_size= 0.8, # proporción del test size\n",
    "                                                    random_state=10) # fijamos random seed para reproducibilidad\n",
    "\n",
    "# creamos el objeto del modelo random forest\n",
    "rf_abstracto = RandomForestClassifier(n_estimators=20, # número de árboles que se van a generar\n",
    "                                      criterion='gini', # criterio de decisión para la construcción de cada árbol\n",
    "                                      max_depth=None, # máximo número de nodos hacia abajo que puede haber. None = infinito\n",
    "                                      min_samples_split=10, # si más de n eventos llegan a una hoja, entonces se vuelve en nodo y se subdivide en dos hojas.\n",
    "                                      max_features=6, # cuántas columnas se van a considerar en la construcción de cada árbol.\n",
    "                                      bootstrap=True, # usar subconjuntos con repetición de la base de datos para construír cada árbol.\n",
    "                                      random_state=10) # semilla aleatoria para reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "# Cross validation va a dividir nuestros datos en n grupos iguales\n",
    "# Despues va a entrenar n modelos usando todas las combinaciones de n-1 conjuntos\n",
    "# Y evaluará cada modelo con el conjunto n-esimo que no usó para entrenar\n",
    "\n",
    "# KFold es un método para definir la forma en la que queremos que queremos que cross validation divida los subconjuntos\n",
    "cross_validation_strategy = KFold(n_splits=10, # número de subconjuntos o 'folds'\n",
    "                                  shuffle=True, # si queremos que se shufleen los datos antes de dividirlos (es bueno ya que vienen ordenados)\n",
    "                                  random_state=10) # semilla aleatoria\n",
    "\n",
    "# ejecutamos cross validation y nos devuelve el score de cada modelo entrenado\n",
    "cross_validation_scores = cross_validate(estimator = rf_abstracto, # el modelo con el cual entrenaremos, ya con hiperparámetros\n",
    "                                         X = X_train, # usamos los conjuntos de entrenamiento\n",
    "                                         y = y_train, # recordemos que ya tienen las y codificadas\n",
    "                                         scoring = 'accuracy',\n",
    "                                         cv = cross_validation_strategy, # aquí podemos dar un número de folds o un objeto que indique la estrategia de foldeo\n",
    "                                         error_score='raise') # raise indica que en caso de error, nos avise y pare la ejecución\n",
    "\n",
    "# enlistamos los resultados\n",
    "lista_resultados = list(cross_validation_scores.get(\"test_score\"))\n",
    "\n",
    "#graficamos\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar([x for x in range(10)],lista_resultados, label = \"precisión\")\n",
    "plt.axhline(mean(lista_resultados), c = 'red')\n",
    "plt.title(\"Resultados cross validation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
