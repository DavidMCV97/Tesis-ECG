{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Obtención de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "En este código se obtiene una segunda lista de datos de interés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paquetes\n",
    "import neurokit2 as nk # incluye herramientas de análisis y detección de ondas de ECG\n",
    "import pandas as pd # para trabajar con DataFrames\n",
    "import numpy as np # para manejar tipos de números\n",
    "import math # para operaciones especiales\n",
    "import statistics # para operaciones especiales\n",
    "import os # para acciones del sistema operativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos una función que nos regrese la información principal de cada ECG\n",
    "def analiza(id_ecg, categoria, senal, sr=100):\n",
    "    \n",
    "    # usamos un try-except para las señales conflictivas\n",
    "    try:\n",
    "        \n",
    "        # primero analizamos la información\n",
    "        senal_limpia = nk.ecg_clean(senal, sampling_rate=sr, method='neurokit') # quitamos el ruido de la señal\n",
    "        aux_rc, picos_R = nk.ecg_peaks(senal_limpia, sampling_rate=sr) # ubicamos los picos de las ondas R\n",
    "        _, picos_otros = nk.ecg_delineate(senal_limpia, picos_R, sampling_rate=sr, method=\"peak\") # ubicamos los otros picos\n",
    "\n",
    "        # segundo calculamos los tiempos entre ondas\n",
    "        ritmo_cardiaco = nk.ecg_rate(aux_rc, sampling_rate=sr)\n",
    "        tiempos_PQ = [(y-x)/sr for x,y in zip(picos_otros['ECG_P_Peaks'],picos_otros['ECG_Q_Peaks'])]\n",
    "        tiempos_QR = [(y-x)/sr for x,y in zip(picos_otros['ECG_Q_Peaks'],picos_R['ECG_R_Peaks'])]\n",
    "        tiempos_RS = [(y-x)/sr for x,y in zip(picos_R['ECG_R_Peaks'],picos_otros['ECG_S_Peaks'])]\n",
    "        tiempos_ST = [(y-x)/sr for x,y in zip(picos_otros['ECG_S_Peaks'],picos_otros['ECG_T_Peaks'])]\n",
    "        tiempos_TP = [(y-x)/sr for x,y in zip(picos_otros['ECG_T_Peaks'][:-1],picos_otros['ECG_P_Peaks'][1:])]\n",
    "\n",
    "        #tercero quitamos nan's\n",
    "        ritmo_cardiaco = [x for x in ritmo_cardiaco if not math.isnan(x)]\n",
    "        tiempos_PQ = [x for x in tiempos_PQ if not math.isnan(x)]\n",
    "        tiempos_QR = [x for x in tiempos_QR if not math.isnan(x)]\n",
    "        tiempos_RS = [x for x in tiempos_RS if not math.isnan(x)]\n",
    "        tiempos_ST = [x for x in tiempos_ST if not math.isnan(x)]\n",
    "        tiempos_TP = [x for x in tiempos_TP if not math.isnan(x)]\n",
    "        \n",
    "        # cuarto calculamos estadisticos de distancias\n",
    "        min_RC = min(ritmo_cardiaco)                # los valores RC están en latidos por minuto (lpm).\n",
    "        media_RC = statistics.mean(ritmo_cardiaco)\n",
    "        max_RC = max(ritmo_cardiaco)             \n",
    "        sd_RC = statistics.stdev(ritmo_cardiaco)\n",
    "        min_PQ = min(tiempos_PQ)                    # los valores de aquí para abajo están en segundos.\n",
    "        media_PQ = statistics.mean(tiempos_PQ)\n",
    "        max_PQ = max(tiempos_PQ)\n",
    "        sd_PQ = statistics.stdev(tiempos_PQ)\n",
    "        min_QR = min(tiempos_QR)\n",
    "        media_QR = statistics.mean(tiempos_QR)\n",
    "        max_QR = max(tiempos_QR)\n",
    "        sd_QR = statistics.stdev(tiempos_QR)\n",
    "        min_RS = min(tiempos_RS)\n",
    "        media_RS = statistics.mean(tiempos_RS)\n",
    "        max_RS = max(tiempos_RS)\n",
    "        sd_RS = statistics.stdev(tiempos_RS)\n",
    "        min_ST = min(tiempos_ST)\n",
    "        media_ST = statistics.mean(tiempos_ST)\n",
    "        max_ST = max(tiempos_ST)\n",
    "        sd_ST = statistics.stdev(tiempos_ST)\n",
    "        min_TP = min(tiempos_TP)\n",
    "        media_TP = statistics.mean(tiempos_TP)\n",
    "        max_TP = max(tiempos_TP)\n",
    "        sd_TP = statistics.stdev(tiempos_TP)\n",
    "        res = [id_ecg, categoria, \n",
    "               min_RC, media_RC, max_RC, sd_RC,\n",
    "               min_PQ, media_PQ, max_PQ, sd_PQ,\n",
    "               min_QR, media_QR, max_QR, sd_QR,\n",
    "               min_RS, media_RS, max_RS, sd_RS,\n",
    "               min_ST, media_ST, max_ST, sd_ST,\n",
    "               min_TP, media_TP, max_TP, sd_TP]\n",
    "\n",
    "    except:\n",
    "        \n",
    "        # en caso de no poder realizar el proceso, regresa una lista de NaN's\n",
    "        res = [None for x in range(24)]\n",
    "        res = [id_ecg, categoria] + res\n",
    "        print(\"except en ecg \" + id_ecg)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos una función que explore los archivos .csv de la carpeta con ECG\n",
    "# y nos regrese un resumen de cada ECG como un renglón de un Data Frame\n",
    "def explorar(direccion, tipo = \".csv\"):\n",
    "\n",
    "    # creamos el dataframe ya con los títulos\n",
    "    df = pd.DataFrame(columns = ['id_ecg', 'categoria', \n",
    "                                 'min_RC', 'media_RC', 'max_RC', 'sd_RC',\n",
    "                                 'min_PQ', 'media_PQ', 'max_PQ', 'sd_PQ',\n",
    "                                 'min_QR', 'media_QR', 'max_QR', 'sd_QR',\n",
    "                                 'min_RS', 'media_RS', 'max_RS', 'sd_RS',\n",
    "                                 'min_ST', 'media_ST', 'max_ST', 'sd_ST',\n",
    "                                 'min_TP', 'media_TP', 'max_TP', 'sd_TP'])\n",
    "    i = 0 # para saber en que renglón vamos\n",
    "    for root, dirs, files in os.walk(direccion): # os.walk va a ingresar a cada carpeta de la dirección y regresar el nombre de los archivos dentro\n",
    "        for name in files: # para cada archivo...\n",
    "            if name.endswith(tipo): # si el archivo es .csv...\n",
    "                id_ecg = name[8:-4] # el nombre es 'patient_####.csv' entonces hacemos slicing para quitar \"patient_\" y \".csv\".\n",
    "                cat = root[13:] # el root es 'Datos_Leonel\\carpeta' y queremos solo la carpeta, hacemos slicing.\n",
    "                archivo = root + \"\\\\\" + name # la dirección del archivo se obtiene concatenando root y file_name\n",
    "                senales = pd.read_csv(archivo, index_col='Unnamed: 0') # las señales están guardadas en formato .csv \n",
    "                senal_II = senales['II'] # Queremos la señal DII\n",
    "                renglon = analiza(id_ecg=id_ecg, categoria=cat, senal=senal_II, sr=100) # aplicamos 'analiza' a DII\n",
    "                df.loc[i,:] = renglon # concatena el resultado de 'analiza' al final del df\n",
    "                i += 1 # contabilizamos el renglón\n",
    "    return df # retornamos el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutamos y guardamos el df para acceder a él más fácilmente\n",
    "# solo como seguridad (para evitar repetir el proceso en vano)\n",
    "# agregamos una llave que debe ajustarse a True si se quiere volver a calcular el dataframe\n",
    "\n",
    "recalcular_df = True # llave\n",
    "nombre_archivo = 'df_datos_tiempos.csv'\n",
    "\n",
    "if recalcular_df:\n",
    "    df1 = explorar(direccion='Datos_Leonel') # hacemos el df\n",
    "    df1 = df1.astype({'id_ecg':float}) # ajustamos dtype\n",
    "    df2 = pd.read_csv('ptbxl_database.csv') # traemos metadata\n",
    "    df1 = df1.merge(df2[['ecg_id','patient_id','age','sex','height','weight']], \n",
    "                      how='left', left_on='id_ecg',right_on='ecg_id',sort=True) # juntamos la data\n",
    "    df1.drop(labels='ecg_id', axis = 1, inplace=True) # eliminamos columna repetida\n",
    "    df1.to_csv(nombre_archivo) # guardamos\n",
    "    print(\"datos analizados y guardados :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
